{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR2pvk_MMHO9",
        "outputId": "2a3cd242-d641-43ca-c97f-0653e3e1c557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF1H1Kq-EVWq",
        "outputId": "f169fa22-7675-430a-e9e8-2f0762ecb08d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6433\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7514\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8034\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8006\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8146\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7992\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8244\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8343\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8357\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8413\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8525\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8638\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8638\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8694\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8834\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8919\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.9101\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9171\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9270\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9312\n",
            "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc3ded88cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.3124 - accuracy: 0.8095\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3123694658279419, 0.8095238208770752]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_dataset = []\n",
        "test_dataset = []\n",
        "\n",
        "image_list = []\n",
        "def create_dataset():\n",
        "    \n",
        "    for filename in glob.glob('/content/drive/*path_to_dataset*/train/Burnt_pizza/*.*'):\n",
        "        im=Image.open(filename)\n",
        "        gray_img = ImageOps.grayscale(im)\n",
        "        gray_resized_img = gray_img.resize(size=(28, 28))\n",
        "\n",
        "        img_final = np.ravel(gray_resized_img) / 255.0\n",
        "        label = np.array([1])\n",
        "        train_dataset.append((img_final, label))\n",
        "\n",
        "    for filename in glob.glob('/content/drive/*path_to_dataset*/train/Good_pizza/*.*'):\n",
        "        im=Image.open(filename)\n",
        "        gray_img = ImageOps.grayscale(im)\n",
        "        gray_resized_img = gray_img.resize(size=(28, 28))\n",
        "\n",
        "        img_final = np.ravel(gray_resized_img) / 255.0\n",
        "        label = np.array([0])\n",
        "        train_dataset.append((img_final, label))\n",
        "\n",
        "    for filename in glob.glob('/content/drive/*path_to_dataset*/test/good/*.*'):\n",
        "        im=Image.open(filename)\n",
        "        gray_img = ImageOps.grayscale(im)\n",
        "        gray_resized_img = gray_img.resize(size=(28, 28))\n",
        "\n",
        "        img_final = np.ravel(gray_resized_img) / 255.0\n",
        "        label = np.array([0])\n",
        "        test_dataset.append((img_final, label))\n",
        "\n",
        "    for filename in glob.glob('/content/drive/*path_to_dataset*/train/burnt/*.*'):\n",
        "        im=Image.open(filename)\n",
        "        gray_img = ImageOps.grayscale(im)\n",
        "        gray_resized_img = gray_img.resize(size=(28, 28))\n",
        "\n",
        "        img_final = np.ravel(gray_resized_img) / 255.0\n",
        "        label = np.array([0])\n",
        "        test_dataset.append((img_final, label))\n",
        "\n",
        "create_dataset()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(np.array([train_dataset[i][0] for i in range(0,len(train_dataset))]),\n",
        "            np.array([train_dataset[i][1] for i in range(0,len(train_dataset))]),\n",
        "            epochs=20)\n",
        "\n",
        "model.evaluate(np.array([test_dataset[i][0] for i in range(0,len(test_dataset))]),\n",
        "                np.array([test_dataset[i][1] for i in range(0,len(test_dataset))]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "pizza.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
